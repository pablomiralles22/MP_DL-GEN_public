{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 2 - Exercise notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CQ1. (â˜†) Create upsampling convolutional models to match a target shape from the input shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are tasked with designing neural network modules that upsample a given input tensor to match a specific target shape using transposed convolutional layers (`nn.ConvTranspose2d`). Your goal is to carefully configure the parameters of each layer, including kernel size, stride, padding, and output padding, to achieve the desired output dimensions.\n",
    "\n",
    "#### Instructions:\n",
    "\n",
    "1. **Input Tensor**: Each exercise provides an input tensor with a specific shape.\n",
    "2. **Target Output Shape**: Your module must upsample the input to match a given target shape.\n",
    "3. **Create a Module**: Define a sequence of transposed convolutional layers using the provided `create_module` function with `nn.ConvTranspose2d` layers to achieve the target shape. **NOTE**: you can do each exercise in an infinite number of ways, with any number of layers.\n",
    "4. **Shape Validation**: After applying the module to the input tensor, ensure the output matches the target shape by using the provided `check_solution` function.\n",
    "5. **Debugging with Hooks**: The `create_module` adds hooks to print the intermediate shapes after each layer to understand the transformations.\n",
    "\n",
    "#### Example Problem:\n",
    "\n",
    "```python\n",
    "# Example Input Tensor\n",
    "input = torch.randn(1, 3, 8, 8)\n",
    "\n",
    "# Target Output Shape: (1, 16, 32, 32)\n",
    "module = create_module([\n",
    "    nn.ConvTranspose2d(3, 8, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ConvTranspose2d(8, 16, kernel_size=3, stride=2, padding=0, output_padding=1),\n",
    "])\n",
    "output = module(input)\n",
    "\n",
    "# Check if the output matches the target shape\n",
    "check_solution((1, 16, 32, 32), output.shape)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_solution(expected_shape, output_shape):\n",
    "    print(\"=\" * 80)\n",
    "    if output_shape != expected_shape:\n",
    "        print(f\"Failure :(. Expected output shape ${expected_shape}, but got {output_shape}\")\n",
    "    else:\n",
    "        print(\"Success!\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_module(layers):\n",
    "    module = nn.Sequential(*layers)\n",
    "    \n",
    "    # Hook to print the output shape after each layer\n",
    "    def hook(module, input, output):\n",
    "        print(f\"Output shape after {module.__class__.__name__}: {output.shape}\")\n",
    "    \n",
    "    # Register the hook for each layer\n",
    "    for layer in module:\n",
    "        if isinstance(layer, nn.ConvTranspose2d):\n",
    "            layer.register_forward_hook(hook)\n",
    "    \n",
    "    return module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape after ConvTranspose2d: torch.Size([1, 8, 15, 15])\n",
      "Output shape after ConvTranspose2d: torch.Size([1, 16, 32, 32])\n",
      "================================================================================\n",
      "Success!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1\n",
    "input = torch.randn(1, 3, 8, 8)\n",
    "module = create_module([\n",
    "    nn.ConvTranspose2d(3, 8, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ConvTranspose2d(8, 16, kernel_size=3, stride=2, padding=0, output_padding=1),\n",
    "])\n",
    "output = module(input)\n",
    "check_solution((1, 16, 32, 32), output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape after ConvTranspose2d: torch.Size([1, 8, 32, 32])\n",
      "================================================================================\n",
      "Success!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2\n",
    "input = torch.randn(1, 1, 16, 16)\n",
    "module = create_module([\n",
    "    nn.ConvTranspose2d(1, 8, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "])\n",
    "output = module(input)\n",
    "check_solution((1, 8, 32, 32), output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape after ConvTranspose2d: torch.Size([1, 10, 24, 24])\n",
      "================================================================================\n",
      "Success!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3\n",
    "input = torch.randn(1, 2, 8, 8)\n",
    "module = create_module([\n",
    "    nn.ConvTranspose2d(2, 10, kernel_size=2, stride=3, output_padding=1),\n",
    "])\n",
    "output = module(input)\n",
    "check_solution((1, 10, 24, 24), output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape after ConvTranspose2d: torch.Size([1, 24, 21, 21])\n",
      "================================================================================\n",
      "Success!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4\n",
    "input = torch.randn(1, 4, 10, 10)\n",
    "module = create_module([\n",
    "    nn.ConvTranspose2d(4, 24, kernel_size=4, stride=2, padding=1, output_padding=1),\n",
    "])\n",
    "output = module(input)\n",
    "check_solution((1, 24, 21, 21), output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape after ConvTranspose2d: torch.Size([1, 8, 16, 16])\n",
      "Output shape after ConvTranspose2d: torch.Size([1, 16, 32, 32])\n",
      "================================================================================\n",
      "Success!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Exercise 5\n",
    "input = torch.randn(1, 5, 7, 7)\n",
    "module = create_module([\n",
    "    nn.ConvTranspose2d(5, 8, kernel_size=3, stride=2, padding=0, output_padding=1),\n",
    "    nn.ConvTranspose2d(8, 16, kernel_size=4, stride=2, padding=1)\n",
    "])\n",
    "output = module(input)\n",
    "check_solution((1, 16, 32, 32), output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape after ConvTranspose2d: torch.Size([1, 24, 26, 26])\n",
      "================================================================================\n",
      "Success!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Exercise 6\n",
    "input = torch.randn(1, 6, 9, 9)\n",
    "module = create_module([\n",
    "    nn.ConvTranspose2d(6, 24, kernel_size=4, stride=3, padding=1),\n",
    "])\n",
    "output = module(input)\n",
    "check_solution((1, 24, 26, 26), output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape after ConvTranspose2d: torch.Size([1, 10, 13, 13])\n",
      "Output shape after ConvTranspose2d: torch.Size([1, 20, 40, 40])\n",
      "================================================================================\n",
      "Success!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Exercise 7\n",
    "input = torch.randn(1, 3, 6, 6)\n",
    "module = create_module([\n",
    "    nn.ConvTranspose2d(3, 10, kernel_size=5, stride=2, padding=1),\n",
    "    nn.ConvTranspose2d(10, 20, kernel_size=6, stride=3, padding=1)\n",
    "])\n",
    "output = module(input)\n",
    "check_solution((1, 20, 40, 40), output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape after ConvTranspose2d: torch.Size([1, 5, 15, 15])\n",
      "Output shape after ConvTranspose2d: torch.Size([1, 10, 29, 29])\n",
      "Output shape after ConvTranspose2d: torch.Size([1, 15, 31, 31])\n",
      "================================================================================\n",
      "Success!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Exercise 8\n",
    "input = torch.randn(1, 1, 8, 8)\n",
    "module = create_module([\n",
    "    nn.ConvTranspose2d(1, 5, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ConvTranspose2d(5, 10, kernel_size=5, stride=2, padding=2),\n",
    "    nn.ConvTranspose2d(10, 15, kernel_size=3, stride=1)\n",
    "])\n",
    "output = module(input)\n",
    "check_solution((1, 15, 31, 31), output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape after ConvTranspose2d: torch.Size([1, 6, 24, 24])\n",
      "Output shape after ConvTranspose2d: torch.Size([1, 24, 50, 50])\n",
      "================================================================================\n",
      "Success!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Exercise 9\n",
    "input = torch.randn(1, 2, 12, 12)\n",
    "module = create_module([\n",
    "    nn.ConvTranspose2d(2, 6, kernel_size=4, stride=2, padding=1),\n",
    "    nn.ConvTranspose2d(6, 24, kernel_size=5, stride=2, padding=1, output_padding=1)\n",
    "])\n",
    "output = module(input)\n",
    "check_solution((1, 24, 50, 50), output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape after ConvTranspose2d: torch.Size([1, 16, 22, 22])\n",
      "Output shape after ConvTranspose2d: torch.Size([1, 64, 44, 44])\n",
      "================================================================================\n",
      "Success!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Exercise 10\n",
    "input = torch.randn(1, 8, 10, 10)\n",
    "module = create_module([\n",
    "    nn.ConvTranspose2d(8, 16, kernel_size=3, stride=2, padding=0, output_padding=1),\n",
    "    nn.ConvTranspose2d(16, 64, kernel_size=4, stride=2, padding=1),\n",
    "])\n",
    "output = module(input)\n",
    "check_solution((1, 64, 44, 44), output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CQ2. (â˜†â˜†) Code the VAE seen in class from scratch, on a dataset of your choosing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select an image dataset that you like, and based on the input size of the images complete the following VAE code seen in class. Check that the model trains and that you can generate new samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The solution depends on the dataset of your choosing.** You can check an example on the lecture notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CQ3. (â˜†â˜†) Modify the VAE code to create a conditional VAE for MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To-Do as part of the evaluation!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
